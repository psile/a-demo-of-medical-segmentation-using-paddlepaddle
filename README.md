# deeplearning/medical segmentation

first solve medical segmentation problem using paddlepaddle


    "# 一、项目背景",
    "医学影像检测任务重，复杂，如果能用计算机辅助检测，结果必定事半功倍\n",
   
    "# 二、数据集简介",
    
    "江苏省大数据开发与应用医疗卫生赛道数据集\n",
   
    "## 1.数据加载和预处理\n",
    
    "构建训练集\n",
    "train_transforms = [\n",
    "    T.RandomHorizontalFlip(),   水平翻转\n",
    "    T.RandomVerticalFlip(),  垂直翻转\n",
    "    T.RandomRotation(),   随机旋转\n",
    "    T.RandomScaleAspect(),   随机缩放\n",
    "    T.RandomDistort(),   随机扭曲\n",
    "    T.Resize(target_size=(256, 256))   这里为了加快速度，改为256x256\n",
    "    T.Normalize()   归一化\n",
    "],
    "train_dataset = Dataset(\n",
    "    transforms=train_transforms,\n",
    "    dataset_root='train',\n",
    "    num_classes=2,\n",
    "    mode='train',\n",
    "    train_path='train/train_list.txt',\n",
    "    #separator=' ',\n",
    ")\n",
    "构建验证集\n",
    "val_transforms = [\n",
    "    T.Resize(target_size=(256, 256)),\n",
    "    T.Normalize()\n",
    "]\n",
    "val_dataset = Dataset(\n",
    "    transforms=val_transforms,\n",
    "    dataset_root='train',\n",
    "    num_classes=2,\n",
    "    mode='val',\n",
    "    val_path='train/val_list.txt',\n",
    "    separator=' ',\n",
    ")\n",
    "\n",
    "\n",
    "# 三、模型选择和开发\n",
    "\n",
    "Unet3+网络：\n",
    "train(\n",
    "    model=unet_3p_model,\n",
    "    train_dataset=train_dataset,\n",
    "    val_dataset=val_dataset,\n",
    "    optimizer=u3p_optimizer,\n",
    "    save_dir='output_u3p',\n",
    "    iters=iters,\n",
    "    batch_size=12,\n",
    "    save_interval=int(iters/5),\n",
    "    log_iters=100,\n",
    "    num_workers=0,\n",
    "    losses=losses,\n",
    "    use_vdl=True)\n",
    " \n",
    "\n",
    "mobilenetv3 分类模型：\n",
    "\n",
    "num_classes = len(train_dataset.labels)\n",
    "model = pdx.cls.MobileNetV3_large_ssld(num_classes=num_classes)\n",
    "model.train(num_epochs=12,\n",
    "            train_dataset=train_dataset,\n",
    "            train_batch_size=32,\n",
    "            eval_dataset=eval_dataset,\n",
    "            lr_decay_epochs=[6, 8],\n",
    "            save_interval_epochs=1,\n",
    "            learning_rate=0.00625,\n",
    "            save_dir='output/mobilenetv3_large_ssld',\n",
    "            use_vdl=True)\n",
    "\n",
    "# 四、效果展示\n",
    "分割：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/85eb45763992481387af53329cb901a125d06019918744d0a8c9e086dfd0023b)\n",
    "分类\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/669337fc50d347c3a8b1b900dbf4ae7ccdc5674b385743f9a299d7a4ce86cffb)\n",
    "\n",
    "\n",
    "# 五、总结与升华\n",
    
    "医学图像分割初步尝试，继续加油\n",
    
    "# 个人简介\n",
    
    "西南大学2019级本科生，医疗图像方向，持续努力"
   ]
